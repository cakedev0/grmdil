{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce notebook sert à créer le modèle graphique suivant : \n",
    "\n",
    "**Format de l'entrée :** \n",
    "- 1ère ligne : $n, m$ deux entiers. $n$ le nombre points, $m$ nombre d'arrêtes.\n",
    "- $n$ lignes suivantes : matrice $P \\in [0, 1]^{n \\times 6}$. $P_{ic} =$ probabilité que le points $i$ soit de label $c$ (d'après le classifier).\n",
    "- $m$ lignes suivantes : arrêtes au format $i, j, d_{ij}$ (de type `int, int, float`)\n",
    "\n",
    "On a $n \\approx 10^6$ et $m \\approx 5 n$\n",
    "\n",
    "**Format de la sorties :**\n",
    "- n lignes : $x \\in \\{1, ..., 6\\}^n$ résulats de la minimisation de l'énergie $E(x)$ avec BP ou TRW. \n",
    "\n",
    "**Energie $E(x)$:**\n",
    "\n",
    "$E(x) = \\sum_{i=1}^n f(P_{i, x_i}) +  \\sum_{(i, j) \\in \\mathcal E} g(d_{ij}) \\mathbb 1_{x_i \\neq x_j} $\n",
    "\n",
    "Avec $f : [0, 1] \\rightarrow \\mathbb R$ décroissante et $g : \\mathbb R_+ \\rightarrow \\mathbb R_+$ décroissante. Pour commencer on peut prendre : \n",
    "\n",
    "$E(x) = \\sum_{i=1}^n - P_{i, x_i} +  \\sum_{(i, j) \\in \\mathcal E} \\alpha \\frac{1}{d_{ij}} \\mathbb 1_{x_i \\neq x_j} $ avec $\\alpha \\in \\mathbb R_+$ à régler \n",
    "\n",
    "Cette modélisation vient exprimer le fait suivant : \"deux points qui sont proches ont une forte chance de partager le même label\". Le but de cette modélisation/minimisation est de trouver des labels $x$ meilleurs que ceux du classifier (qui sont les $(\\arg\\max_c P_{ic})_i$).\n",
    "\n",
    "**Score** :\n",
    "\n",
    "Le score est calculer par rapports aux vrais labels $x^{true} \\in \\{0, 1, ..., 6\\}^n$ (le label $0$ représente les \"unclassifed\". Les points \"unclassifed\" n'interviennent pas dans le score.) \n",
    "\n",
    "$\\text{Score}(x^{true}, x) = \\frac 1 6 \\sum_{c = 1}^6 \\text{IoU}(x^{true}, x, c)$ où $\\text{IoU}$ signifie Intersection over Union : $$\\text{IoU}(x^{true}, x, c) = \\frac{ \\{i, x^{true}_i = c\\} \\cap  \\{i, x_i = c\\} }{\\{i, x^{true}_i = c\\} \\cup  \\{i, x_i = c \\text{ et } x^{true}_i \\neq 0\\}}$$\n",
    "\n",
    "Pour l'instant, le classifier fait environ $0.45$ mais est très mauvais sur certaines classes (les piétons notamment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pickle\n",
    "from ply import write_ply, read_ply\n",
    "from utils import neighborhood, min_radius_max_knns, local_PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {0: 'Unclassified', 1: 'Ground', 2: 'Building', 3: 'Poles',\n",
    "               4: 'Pedestrians', 5: 'Cars', 6: 'Vegetation'}\n",
    "\n",
    "class CloudDataset:\n",
    "    \n",
    "    def __init__(self, name, points, labels=None):\n",
    "        self.name = name\n",
    "        self.points = points\n",
    "        self.labels = labels\n",
    "    \n",
    "    def compute_neighborhoods(self, radius=0.25, k=300):\n",
    "        self.neighs, self.eigvals, self.eigvs = neighborhood(self.points, radius=0.25, k=300)\n",
    "    \n",
    "    def compute_features(self, feature_functions):\n",
    "        features = []\n",
    "        for func in feature_functions:\n",
    "            f = func(self.neighs, self.eigvals, self.eigvs)\n",
    "            if(f.ndim == 1):\n",
    "                f = f.reshape(-1, 1)\n",
    "            features.append(f)\n",
    "        self.features = np.concatenate(features, axis=1)\n",
    "       \n",
    "    @property\n",
    "    def X(self):\n",
    "        if(self.labels is None):\n",
    "            return self.features\n",
    "        else:\n",
    "            return self.features[self.labels > 0, :]\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        if(self.labels is None):\n",
    "            return -np.ones(self.points.shape[0])\n",
    "        else:\n",
    "            return self.labels[self.labels > 0] - 1\n",
    "    \n",
    "    def save_neighborhoods(self, fname=None):\n",
    "        if(fname is None):\n",
    "            fname = f\"data/{self.name}.pkl\"\n",
    "        data = [self.neighs, self.eigvals, self.eigvs]\n",
    "        with open(fname, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "            \n",
    "    def load_neighborhoods(self, fname=None):\n",
    "        if(fname is None):\n",
    "            fname = f\"data/{self.name}.pkl\"\n",
    "        with open(fname, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        self.neighs, self.eigvals, self.eigvs = data\n",
    "        \n",
    "    def add_ground_distance_feature(self, ground_bidx=None):\n",
    "        if(ground_bidx is None):\n",
    "            ground_bidx = self.labels == 1\n",
    "        ground = self.points[ground_bidx, :]\n",
    "        eigvals, eigvects = local_PCA(ground)\n",
    "        g0 = ground.mean(axis=0)\n",
    "        points_grounded = (self.points - g0) @ eigvects\n",
    "        self.features = np.concatenate((self.features, points_grounded[:, [2]]), axis=1)\n",
    "        \n",
    "    def unlabel(self):\n",
    "        if(self.labels is not None):\n",
    "            self.mem_labels = self.labels\n",
    "            self.labels = None\n",
    "        \n",
    "    def relabel(self):\n",
    "        if(self.labels is None):\n",
    "            self.labels = self.mem_labels\n",
    "        \n",
    "    def __repr__(self):\n",
    "        labeled = \"unlabeled\" if self.labels is None else \"labeled\"\n",
    "        return f\"CloudDataset<{self.name}, {self.points.shape[0]} points, {labeled}>\"\n",
    "    \n",
    "class MultiDataset:\n",
    "    \n",
    "    def __init__(self, datasets, test_idx=1):\n",
    "        self.datasets = datasets\n",
    "        self.test_idx = test_idx\n",
    "        \n",
    "    def train_test_split(self):\n",
    "        self.testset.unlabel()\n",
    "        ys, Xs = [], []\n",
    "        for dataset in self.trainsets:\n",
    "            dataset.relabel()\n",
    "            Xs.append(dataset.X)\n",
    "            ys.append(dataset.y)\n",
    "        \n",
    "        X_train = np.concatenate(Xs, axis=0)\n",
    "        y_train = np.concatenate(ys)\n",
    "        return X_train, self.testset.X, y_train, self.testset.mem_labels\n",
    "    \n",
    "    @property\n",
    "    def testset(self):\n",
    "        return self.datasets[self.test_idx]\n",
    "    \n",
    "    @property\n",
    "    def trainsets(self):\n",
    "        datasets = self.datasets[:]\n",
    "        datasets.pop(self.test_idx)\n",
    "        return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CloudDataset<paris1, 1896865 points, labeled>,\n",
       " CloudDataset<paris2, 2262453 points, labeled>,\n",
       " CloudDataset<lille1, 1901853 points, labeled>,\n",
       " CloudDataset<lille2, 2500428 points, labeled>,\n",
       " CloudDataset<dijon, 3079187 points, unlabeled>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_points(fname):\n",
    "    cloud_ply = read_ply(fname)\n",
    "    points = np.vstack((cloud_ply['x'], cloud_ply['y'], cloud_ply['z'])).T\n",
    "    if('class' in cloud_ply.dtype.fields):\n",
    "        labels = cloud_ply['class']\n",
    "        return points, labels\n",
    "    else:\n",
    "        return points\n",
    "\n",
    "paris, paris_labels = load_points(\"data/MiniParis1.ply\")\n",
    "lille1, lille1_labels = load_points(\"data/MiniLille1.ply\")\n",
    "lille2, lille2_labels = load_points(\"data/MiniLille2.ply\")\n",
    "dijon = load_points(\"data/MiniDijon9.ply\")\n",
    "paris_wh = paris[:, 1] <= 20\n",
    "paris1, paris1_label = paris[paris_wh], paris_labels[paris_wh]\n",
    "paris2, paris2_label = paris[~paris_wh], paris_labels[~paris_wh]\n",
    "\n",
    "datasets = [\n",
    "    CloudDataset(\"paris1\", paris1, paris1_label),\n",
    "    CloudDataset(\"paris2\", paris2, paris2_label),\n",
    "    CloudDataset(\"lille1\", lille1, lille1_labels),\n",
    "    CloudDataset(\"lille2\", lille2, lille2_labels),\n",
    "    CloudDataset(\"dijon\", dijon)\n",
    "]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- paris1 neighborhoods loaded --\n",
      "-- paris2 neighborhoods loaded --\n",
      "-- lille1 neighborhoods loaded --\n",
      "-- lille2 neighborhoods loaded --\n",
      "-- dijon neighborhoods loaded --\n"
     ]
    }
   ],
   "source": [
    "recompute = False\n",
    "\n",
    "if(recompute):\n",
    "    for dataset in datasets:\n",
    "        dataset.compute_neighborhoods(radius=0.15, k=100)\n",
    "        dataset.save_neighborhoods()\n",
    "        print(f\"-- {dataset.name} neighborhoods computed --\")\n",
    "else:\n",
    "    for dataset in datasets:\n",
    "        dataset.load_neighborhoods()\n",
    "        print(f\"-- {dataset.name} neighborhoods loaded --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def compute_4(an, eigvals, eigs):\n",
    "    verticality = 2/np.pi * np.arcsin(np.abs(eigs[:, -1, -1]))\n",
    "    linearity = 1 - eigvals[:, 1] / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    planarity = (eigvals[:, 1] - eigvals[:, 2]) / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    sphericity = eigvals[:, 2] / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    return np.vstack((verticality, linearity, planarity, sphericity)).T\n",
    "\n",
    "def raw_eigenvalues(an, eigvals, eigs):\n",
    "    return eigvals\n",
    "\n",
    "def raw_eigenvector(an, eigvals, eigs):\n",
    "    return eigs.reshape(-1, 9)\n",
    "\n",
    "def density(ans, eigvals, eigs):\n",
    "    return np.array([ns.size for ns in ans], dtype=float).reshape(-1, 1)\n",
    "\n",
    "feature_functions = [compute_4, raw_eigenvalues, raw_eigenvector, density]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.compute_features(feature_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 14))\n",
    "# for i, data in enumerate(datas):\n",
    "#     plt.subplot(5, 1, i+1)\n",
    "#     plt.hist([ns.size for ns in data[0]], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([199742, 790686, 501958,  14467,  10567,  37790, 707243])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 1\n",
    "train_multidataset = MultiDataset(datasets[:-1], test_idx)\n",
    "X_train, X_test, y_train, labels_test = train_multidataset.train_test_split()\n",
    "np.bincount(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "param = {'num_leaves': 31, 'max_depth': -1, 'objective': 'multiclass', 'num_class': 6, 'max_bin': 30}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "y_pred = np.concatenate((np.zeros((X_test.shape[0], 1)), bst.predict(X_test)), axis=1) \n",
    "labels_pred = np.argmax(y_pred[:, 1:], axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.45656655547717073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 - Ground</th>\n",
       "      <td>0.944945</td>\n",
       "      <td>0.965382</td>\n",
       "      <td>0.924908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 - Building</th>\n",
       "      <td>0.626729</td>\n",
       "      <td>0.861086</td>\n",
       "      <td>0.714446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - Poles</th>\n",
       "      <td>0.290129</td>\n",
       "      <td>0.207645</td>\n",
       "      <td>0.140861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 - Pedestrians</th>\n",
       "      <td>0.082372</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.016320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 - Cars</th>\n",
       "      <td>0.510388</td>\n",
       "      <td>0.150172</td>\n",
       "      <td>0.139634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 - Vegetation</th>\n",
       "      <td>0.851386</td>\n",
       "      <td>0.892152</td>\n",
       "      <td>0.803230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall       IoU\n",
       "1 - Ground        0.944945  0.965382  0.924908\n",
       "2 - Building      0.626729  0.861086  0.714446\n",
       "3 - Poles         0.290129  0.207645  0.140861\n",
       "4 - Pedestrians   0.082372  0.018927  0.016320\n",
       "5 - Cars          0.510388  0.150172  0.139634\n",
       "6 - Vegetation    0.851386  0.892152  0.803230"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_results(labels_test, labels_pred):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    IoUs = []\n",
    "    for c in range(1, 7):\n",
    "        precisions.append(np.mean(labels_test[labels_pred == c] == c))\n",
    "        recalls.append(np.mean(labels_pred[labels_test == c] == c))\n",
    "        IoUs.append(np.sum((labels_pred == c) & (labels_test == c)) / \\\n",
    "                    np.sum(((labels_pred == c) & (labels_test != 0)) | (labels_test == c)))\n",
    "        \n",
    "\n",
    "    return pd.DataFrame({\"precision\": precisions, \"recall\": recalls, \"IoU\": IoUs}, \n",
    "                        index=[str(i) + \" - \" + label_names[i] for i in range(1, 7)])\n",
    "\n",
    "res = print_results(labels_test, labels_pred)\n",
    "print(\"Score:\", res[\"IoU\"].mean())\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = 4\n",
    "# idxs_c = np.argsort(y_pred[:, c])[::-1][:10]\n",
    "# print(np.bincount(labels_test[idxs_c]) / idxs_c.size)\n",
    "# print(np.bincount(labels_test[idxs_c])[c] / idxs_c.size)\n",
    "# plt.plot(y_pred[idxs_c, c])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
