{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour éxécuter ce notebook : \n",
    "\n",
    "- télécharger les données 3d ici https://we.tl/t-g9Y9v6dROU et les placer dans le répertoire `3d_data/`\n",
    "- ce code est assez \"computationally intensive\", mieux vaut une bonne machine pour l'éxecuter\n",
    "- les données de sortie peuvent être télécharger directement ici : https://we.tl/t-lUM3emszGz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce notebook sert à créer le modèle graphique suivant : \n",
    "\n",
    "**Format de l'entrée :** \n",
    "- 1ère ligne : $n, m$ deux entiers. $n$ le nombre points, $m$ nombre d'arrêtes.\n",
    "- $n$ lignes suivantes : matrice $P \\in [0, 1]^{n \\times 6}$. $P_{ic} =$ probabilité que le points $i$ soit de label $c$ (d'après le classifier).\n",
    "- $m$ lignes suivantes : arrêtes au format $i, j, d_{ij} \\in \\{0, ..., n-1\\} \\times \\{0, ..., n-1\\} \\times \\mathbb R_+$ \n",
    "\n",
    "On a $n \\approx 10^6$ et $m \\approx 5 n$\n",
    "\n",
    "**Format de la sorties :**\n",
    "- n lignes : $x \\in \\{1, ..., 6\\}^n$ résulats de la minimisation de l'énergie $E(x)$ avec BP ou TRW. \n",
    "\n",
    "**Energie $E(x)$:**\n",
    "\n",
    "$E(x) = \\sum_{i=1}^n f_{x_i}(P_{i, x_i}) +  \\sum_{(i, j) \\in \\mathcal E} g(d_{ij}) \\mathbb 1_{x_i \\neq x_j} $\n",
    "\n",
    "Avec les $f_c : [0, 1] \\rightarrow \\mathbb R_-$ décroissantes et $g : \\mathbb R_+ \\rightarrow \\mathbb R_+$ décroissante. Pour commencer on peut prendre : \n",
    "\n",
    "$E(x) = \\sum_{i=1}^n - \\eta_{x_i} P_{i, x_i} +  \\sum_{(i, j) \\in \\mathcal E} \\alpha \\frac{1}{\\beta + d_{ij}} \\mathbb 1_{x_i \\neq x_j} $ avec $\\alpha, \\beta > 0$ à régler et $\\eta_{c} = \\sqrt{\\frac{\\sum_{i, k} P_{i, k}}{\\sum_i P_{i,c}}}$\n",
    "\n",
    "Cette modélisation vient exprimer le fait suivant : \"deux points qui sont proches ont une forte chance de partager le même label\". Le but de cette modélisation/minimisation est de trouver des labels $x$ meilleurs que ceux du classifier (qui sont les $(\\arg\\max_c P_{ic})_i$).\n",
    "\n",
    "**Score** :\n",
    "\n",
    "Le score est calculer par rapports aux vrais labels $x^{true} \\in \\{0, 1, ..., 6\\}^n$ (le label $0$ représente les \"unclassifed\". Les points \"unclassifed\" n'interviennent pas dans le score.) \n",
    "\n",
    "$\\text{Score}(x^{true}, x) = \\frac 1 6 \\sum_{c = 1}^6 \\text{IoU}(x^{true}, x, c)$ où $\\text{IoU}$ signifie Intersection over Union : $$\\text{IoU}(x^{true}, x, c) = \\frac{ \\{i, x^{true}_i = c\\} \\cap  \\{i, x_i = c\\} }{\\{i, x^{true}_i = c\\} \\cup  \\{i, x_i = c \\text{ et } x^{true}_i \\neq 0\\}}$$\n",
    "\n",
    "\n",
    "Le classifier fait entre $0.35$ et $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "from cloudpoints import load_points\n",
    "from datasets import CloudDataset, MultiDataset, label_names, df_results\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données 3d\n",
    "\n",
    "Il y a 4 jeux de données :\n",
    "- `paris1`\n",
    "- `paris2`\n",
    "- `lille1`\n",
    "- `lille2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CloudDataset<paris1, 1896865 points, labeled>,\n",
       " CloudDataset<paris2, 2262453 points, labeled>,\n",
       " CloudDataset<lille1, 1901853 points, labeled>,\n",
       " CloudDataset<lille2, 2500428 points, labeled>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"3d_data/\")\n",
    "\n",
    "paris, paris_labels = load_points(data_path / \"MiniParis1.ply\")\n",
    "lille1, lille1_labels = load_points(data_path / \"MiniLille1.ply\")\n",
    "lille2, lille2_labels = load_points(data_path / \"MiniLille2.ply\")\n",
    "dijon = load_points(data_path / \"MiniDijon9.ply\")\n",
    "paris_wh = paris[:, 1] <= 20\n",
    "paris1, paris1_label = paris[paris_wh], paris_labels[paris_wh]\n",
    "paris2, paris2_label = paris[~paris_wh], paris_labels[~paris_wh]\n",
    "\n",
    "datasets = [\n",
    "    CloudDataset(\"paris1\", paris1, paris1_label),\n",
    "    CloudDataset(\"paris2\", paris2, paris2_label),\n",
    "    CloudDataset(\"lille1\", lille1, lille1_labels),\n",
    "    CloudDataset(\"lille2\", lille2, lille2_labels)\n",
    "]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs des voisinages (à plusieurs échelles) de chaque points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset.compute_neighborhoods([(300, 0.25), (150, 0.15), (50, 0.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs de features locales : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def compute_4(an, eigvals, eigs):\n",
    "    verticality = 2/np.pi * np.arcsin(np.abs(eigs[:, -1, -1]))\n",
    "    linearity = 1 - eigvals[:, 1] / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    planarity = (eigvals[:, 1] - eigvals[:, 2]) / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    sphericity = eigvals[:, 2] / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    return np.vstack((verticality, linearity, planarity, sphericity)).T\n",
    "\n",
    "def raw_eigenvalues(an, eigvals, eigs):\n",
    "    return eigvals\n",
    "\n",
    "def raw_eigenvector(an, eigvals, eigs):\n",
    "    return eigs.reshape(-1, 9)\n",
    "\n",
    "def density(ans, eigvals, eigs):\n",
    "    return np.array([ns.size for ns in ans], dtype=float).reshape(-1, 1)\n",
    "\n",
    "feature_functions = [compute_4, raw_eigenvalues, raw_eigenvector, density]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.compute_features(feature_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement d'un classifier et résultats sur `paris2`\n",
    "\n",
    "Le classifier est entrainé sur `paris1`, `lille1`, `lille2` et testé sur `paris2` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([199742, 790686, 501958,  14467,  10567,  37790, 707243])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 1\n",
    "train_multidataset = MultiDataset(datasets, test_idx)\n",
    "X_train, X_test, y_train, labels_test = train_multidataset.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02194104, 0.42954246, 0.40030547, 0.0052367 , 0.        ,\n",
       "       0.03844622, 0.1045281 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = np.bincount(labels_test) \n",
    "freq = freq / freq.sum()\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4736162489171199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 - Ground</th>\n",
       "      <td>0.948693</td>\n",
       "      <td>0.952100</td>\n",
       "      <td>0.917495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 - Building</th>\n",
       "      <td>0.634104</td>\n",
       "      <td>0.859002</td>\n",
       "      <td>0.719627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - Poles</th>\n",
       "      <td>0.596179</td>\n",
       "      <td>0.220018</td>\n",
       "      <td>0.195877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 - Pedestrians</th>\n",
       "      <td>0.333260</td>\n",
       "      <td>0.144317</td>\n",
       "      <td>0.118714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 - Cars</th>\n",
       "      <td>0.468369</td>\n",
       "      <td>0.088357</td>\n",
       "      <td>0.084589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 - Vegetation</th>\n",
       "      <td>0.835188</td>\n",
       "      <td>0.911537</td>\n",
       "      <td>0.805395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall       IoU\n",
       "1 - Ground        0.948693  0.952100  0.917495\n",
       "2 - Building      0.634104  0.859002  0.719627\n",
       "3 - Poles         0.596179  0.220018  0.195877\n",
       "4 - Pedestrians   0.333260  0.144317  0.118714\n",
       "5 - Cars          0.468369  0.088357  0.084589\n",
       "6 - Vegetation    0.835188  0.911537  0.805395"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_round = 50\n",
    "param = {'num_leaves': 31, 'max_depth': -1, 'objective': 'multiclass', 'num_class': 6, 'max_bin': 30}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "y_pred = np.concatenate((np.zeros((X_test.shape[0], 1)), bst.predict(X_test)), axis=1) \n",
    "labels_pred = np.argmax(y_pred[:, 1:], axis=1) + 1\n",
    "\n",
    "res = df_results(labels_test, labels_pred)\n",
    "print(\"Score:\", res[\"IoU\"].mean())\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création et sauvegarde de l'entrée décrite ci-dessus pour chaque dataset : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg IoU: 0.36206471884456626\n",
      "Worst class : 5 - Cars | IoU: 0.014310664626798987\n",
      "avg IoU: 0.4826614824699731\n",
      "Worst class : 4 - Pedestrians | IoU: 0.10407169898786989\n",
      "avg IoU: 0.4407801774965228\n",
      "Worst class : 3 - Poles | IoU: 0.03163660598991961\n",
      "avg IoU: 0.5040229855883136\n",
      "Worst class : 5 - Cars | IoU: 0.11176871622088945\n"
     ]
    }
   ],
   "source": [
    "grm_path = Path(\"GRM_data\")\n",
    "if(not grm_path.exists()):\n",
    "    grm_path.mkdir()\n",
    "\n",
    "for dataset_idx in [0, 1, 2, 3]:\n",
    "    train_multidataset = MultiDataset(datasets, dataset_idx)\n",
    "    X_train, X_test, y_train, labels_test = train_multidataset.train_test_split()\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    bst = lgb.train(param, train_data, num_round)\n",
    "    y_pred = np.concatenate((np.zeros((X_test.shape[0], 1)), bst.predict(X_test)), axis=1) \n",
    "    labels_pred = np.argmax(y_pred[:, 1:], axis=1) + 1\n",
    "    \n",
    "    res = df_results(labels_test, labels_pred)\n",
    "    print(\"avg IoU:\", res[\"IoU\"].mean())\n",
    "    worst_class = res[\"IoU\"].idxmin()\n",
    "    print(\"Worst class :\", worst_class, \"| IoU:\", res.loc[worst_class, \"IoU\"])\n",
    "    \n",
    "    datasets[dataset_idx].write_GRM(y_pred[:, 1:], grm_path, grm_k=15, grm_radius=0.1, grm_min_k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
