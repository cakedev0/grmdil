{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour éxécuter ce notebook : \n",
    "\n",
    "- télécharger les données 3d ici https://we.tl/t-g9Y9v6dROU et les placer dans le répertoire `3d_data/`\n",
    "- créer un le répertoire `GRM_data/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ce notebook sert à créer le modèle graphique suivant : \n",
    "\n",
    "Lien de téléchargement : \n",
    "\n",
    "**Format de l'entrée :** \n",
    "- 1ère ligne : $n, m$ deux entiers. $n$ le nombre points, $m$ nombre d'arrêtes.\n",
    "- $n$ lignes suivantes : matrice $P \\in [0, 1]^{n \\times 6}$. $P_{ic} =$ probabilité que le points $i$ soit de label $c$ (d'après le classifier).\n",
    "- $m$ lignes suivantes : arrêtes au format $i, j, d_{ij} \\in \\{0, ..., n-1\\} \\times \\{0, ..., n-1\\} \\times \\mathbb R_+$ \n",
    "\n",
    "On a $n \\approx 10^6$ et $m \\approx 5 n$\n",
    "\n",
    "**Format de la sorties :**\n",
    "- n lignes : $x \\in \\{1, ..., 6\\}^n$ résulats de la minimisation de l'énergie $E(x)$ avec BP ou TRW. \n",
    "\n",
    "**Energie $E(x)$:**\n",
    "\n",
    "$E(x) = \\sum_{i=1}^n f(P_{i, x_i}) +  \\sum_{(i, j) \\in \\mathcal E} g(d_{ij}) \\mathbb 1_{x_i \\neq x_j} $\n",
    "\n",
    "Avec $f : [0, 1] \\rightarrow \\mathbb R$ décroissante et $g : \\mathbb R_+ \\rightarrow \\mathbb R_+$ décroissante. Pour commencer on peut prendre : \n",
    "\n",
    "$E(x) = \\sum_{i=1}^n - P_{i, x_i} +  \\sum_{(i, j) \\in \\mathcal E} \\alpha \\frac{1}{d_{ij}} \\mathbb 1_{x_i \\neq x_j} $ avec $\\alpha \\in \\mathbb R_+$ à régler \n",
    "\n",
    "Cette modélisation vient exprimer le fait suivant : \"deux points qui sont proches ont une forte chance de partager le même label\". Le but de cette modélisation/minimisation est de trouver des labels $x$ meilleurs que ceux du classifier (qui sont les $(\\arg\\max_c P_{ic})_i$).\n",
    "\n",
    "**Score** :\n",
    "\n",
    "Le score est calculer par rapports aux vrais labels $x^{true} \\in \\{0, 1, ..., 6\\}^n$ (le label $0$ représente les \"unclassifed\". Les points \"unclassifed\" n'interviennent pas dans le score.) \n",
    "\n",
    "$\\text{Score}(x^{true}, x) = \\frac 1 6 \\sum_{c = 1}^6 \\text{IoU}(x^{true}, x, c)$ où $\\text{IoU}$ signifie Intersection over Union : $$\\text{IoU}(x^{true}, x, c) = \\frac{ \\{i, x^{true}_i = c\\} \\cap  \\{i, x_i = c\\} }{\\{i, x^{true}_i = c\\} \\cup  \\{i, x_i = c \\text{ et } x^{true}_i \\neq 0\\}}$$\n",
    "\n",
    "\n",
    "Le classifier fait entre $0.35$ et $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "from cloudpoints import load_points\n",
    "from datasets import CloudDataset, MultiDataset, label_names\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CloudDataset<paris1, 1896865 points, labeled>,\n",
       " CloudDataset<paris2, 2262453 points, labeled>,\n",
       " CloudDataset<lille1, 1901853 points, labeled>,\n",
       " CloudDataset<lille2, 2500428 points, labeled>,\n",
       " CloudDataset<dijon, 3079187 points, unlabeled>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"3d_data/\")\n",
    "\n",
    "paris, paris_labels = load_points(data_path / \"MiniParis1.ply\")\n",
    "lille1, lille1_labels = load_points(data_path / \"MiniLille1.ply\")\n",
    "lille2, lille2_labels = load_points(data_path / \"MiniLille2.ply\")\n",
    "dijon = load_points(data_path / \"MiniDijon9.ply\")\n",
    "paris_wh = paris[:, 1] <= 20\n",
    "paris1, paris1_label = paris[paris_wh], paris_labels[paris_wh]\n",
    "paris2, paris2_label = paris[~paris_wh], paris_labels[~paris_wh]\n",
    "\n",
    "datasets = [\n",
    "    CloudDataset(\"paris1\", paris1, paris1_label),\n",
    "    CloudDataset(\"paris2\", paris2, paris2_label),\n",
    "    CloudDataset(\"lille1\", lille1, lille1_labels),\n",
    "    CloudDataset(\"lille2\", lille2, lille2_labels),\n",
    "    CloudDataset(\"dijon\", dijon)\n",
    "]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset.compute_neighborhoods([(300, 0.25), (150, 0.15), (50, 0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n",
      "/home/infres/alacote/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def compute_4(an, eigvals, eigs):\n",
    "    verticality = 2/np.pi * np.arcsin(np.abs(eigs[:, -1, -1]))\n",
    "    linearity = 1 - eigvals[:, 1] / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    planarity = (eigvals[:, 1] - eigvals[:, 2]) / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    sphericity = eigvals[:, 2] / np.minimum(eigvals[:, 0], 1e-8)\n",
    "    return np.vstack((verticality, linearity, planarity, sphericity)).T\n",
    "\n",
    "def raw_eigenvalues(an, eigvals, eigs):\n",
    "    return eigvals\n",
    "\n",
    "def raw_eigenvector(an, eigvals, eigs):\n",
    "    return eigs.reshape(-1, 9)\n",
    "\n",
    "def density(ans, eigvals, eigs):\n",
    "    return np.array([ns.size for ns in ans], dtype=float).reshape(-1, 1)\n",
    "\n",
    "feature_functions = [compute_4, raw_eigenvalues, raw_eigenvector, density]\n",
    "\n",
    "for dataset in datasets:\n",
    "    dataset.compute_features(feature_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([199742, 790686, 501958,  14467,  10567,  37790, 707243])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 1\n",
    "train_multidataset = MultiDataset(datasets[:-1], test_idx)\n",
    "X_train, X_test, y_train, labels_test = train_multidataset.train_test_split()\n",
    "np.bincount(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 50\n",
    "param = {'num_leaves': 31, 'max_depth': -1, 'objective': 'multiclass', 'num_class': 6, 'max_bin': 30}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "y_pred = np.concatenate((np.zeros((X_test.shape[0], 1)), bst.predict(X_test)), axis=1) \n",
    "labels_pred = np.argmax(y_pred[:, 1:], axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4826614824699731\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 - Ground</th>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.968637</td>\n",
       "      <td>0.928423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 - Building</th>\n",
       "      <td>0.634608</td>\n",
       "      <td>0.873523</td>\n",
       "      <td>0.731533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - Poles</th>\n",
       "      <td>0.497966</td>\n",
       "      <td>0.253888</td>\n",
       "      <td>0.209742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 - Pedestrians</th>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.127472</td>\n",
       "      <td>0.104072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 - Cars</th>\n",
       "      <td>0.508233</td>\n",
       "      <td>0.115983</td>\n",
       "      <td>0.111357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 - Vegetation</th>\n",
       "      <td>0.858031</td>\n",
       "      <td>0.897464</td>\n",
       "      <td>0.810842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 precision    recall       IoU\n",
       "1 - Ground        0.944321  0.968637  0.928423\n",
       "2 - Building      0.634608  0.873523  0.731533\n",
       "3 - Poles         0.497966  0.253888  0.209742\n",
       "4 - Pedestrians   0.284959  0.127472  0.104072\n",
       "5 - Cars          0.508233  0.115983  0.111357\n",
       "6 - Vegetation    0.858031  0.897464  0.810842"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_results(labels_test, labels_pred):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    IoUs = []\n",
    "    for c in range(1, 7):\n",
    "        if(np.sum(labels_test == c) == 0):\n",
    "            precisions.append(1)\n",
    "            recalls.append(1)\n",
    "            IoUs.append(1)\n",
    "        else:\n",
    "            precisions.append(np.mean(labels_test[labels_pred == c] == c))\n",
    "            recalls.append(np.mean(labels_pred[labels_test == c] == c))\n",
    "            IoUs.append(np.sum((labels_pred == c) & (labels_test == c)) / \\\n",
    "                        np.sum(((labels_pred == c) & (labels_test != 0)) | (labels_test == c)))\n",
    "        \n",
    "\n",
    "    return pd.DataFrame({\"precision\": precisions, \"recall\": recalls, \"IoU\": IoUs}, \n",
    "                        index=[str(i) + \" - \" + label_names[i] for i in range(1, 7)])\n",
    "\n",
    "res = print_results(labels_test, labels_pred)\n",
    "print(\"Score:\", res[\"IoU\"].mean())\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the Graphical Model as described above (and the corresponding labels) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neighborhoods:\n",
    "    \n",
    "    def __init__(self, points, neigh_idxs=None, distances=None, k=None):\n",
    "        self.points = points\n",
    "        self.n = points.shape[0]\n",
    "        if(k is None):\n",
    "            self.neigh_idxs = neigh_idxs\n",
    "            self.distances = distances\n",
    "        else:\n",
    "            kdt = KDTree(points)\n",
    "            self.distances, self.neigh_idxs = kdt.query(points, k=k)\n",
    "    \n",
    "    def restrict(self, k=10000, radius=1e9, inplace=False):\n",
    "        whs = [ds < radius for ds in self.distances]\n",
    "        for wh in whs:\n",
    "            wh[k:] = False\n",
    "        res_neigh_idxs = []\n",
    "        res_distances = []\n",
    "        for wh, ns, ds in zip(whs, self.neigh_idxs, self.distances):\n",
    "            res_neigh_idxs.append(ns[wh])\n",
    "            res_distances.append(ds[wh])\n",
    "        if(inplace):\n",
    "            self.neigh_idxs = res_neigh_idxs\n",
    "            self.distances = res_distances\n",
    "            return self\n",
    "        else:\n",
    "            return Neighborhoods(self.points, res_neigh_idxs, res_distances)\n",
    "    \n",
    "    def compute_local_PCAs(self):\n",
    "        self.eigenvalues = np.zeros((self.n, 3))\n",
    "        self.eigenvectors = np.zeros((self.n, 3, 3))\n",
    "        for i, ns in enumerate(self.neigh_idxs):\n",
    "            neighs = self.points[ns, :]\n",
    "            eigvals, eigvects = local_PCA(neighs)\n",
    "            self.eigenvalues[i, :] = eigvals\n",
    "            self.eigenvectors[i, :] = eigvects\n",
    "            \n",
    "    def get_features(self, feature_functions):\n",
    "        features = []\n",
    "        neighs = [self.points[ns, :] for ns in self.neigh_idxs]\n",
    "        for func in feature_functions:\n",
    "            f = func(neighs, self.eigenvalues, self.eigenvectors)\n",
    "            if(f.ndim == 1):\n",
    "                f = f.reshape(-1, 1)\n",
    "            features.append(f)\n",
    "        return np.concatenate(features, axis=1)\n",
    "    \n",
    "    def get_edges(self):\n",
    "        m = np.sum([ns.size for ns in self.neigh_idxs])\n",
    "        edges = np.zeros((m, 2), dtype=int)\n",
    "        j = 0\n",
    "        for i, ns in enumerate(self.neigh_idxs):\n",
    "            edges[j:j + ns.size, 0] = i\n",
    "            edges[j:j + ns.size, 1] = ns\n",
    "            j += ns.size\n",
    "        edges = edges[:j, :]\n",
    "        edges = edges[edges[:, 0] != edges[:, 1], :]\n",
    "        edges = drop_duplicated_rows(edges)\n",
    "        distances = np.linalg.norm(self.points[edges[:, 0], :] - self.points[edges[:, 1], :], axis=1)\n",
    "        return edges, distances\n",
    "    \n",
    "from cloudpoints import drop_duplicated_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets[0]\n",
    "nb = Neighborhoods(ds.points, ds.neighborhoods[-1].neigh_idxs, ds.neighborhoods[-1].distances)\n",
    "edges, _ = nb.restrict(k=12, radius=0.085).get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = ds.neighborhoods[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_idx in [0, 1, 2, 3]:\n",
    "    dataset = datasets[dataset_idx]\n",
    "    new_nbs = []\n",
    "    for nb in dataset.neighborhoods:\n",
    "        new_nb = Neighborhoods(nb.points, nb.neigh_idxs, nb.distances)\n",
    "        new_nb.eigenvalues = nb.eigenvalues\n",
    "        new_nb.eigenvectors = nb.eigenvectors\n",
    "        new_nbs.append(new_nb)\n",
    "    dataset.neighborhoods = new_nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg IoU: 0.36206471884456626\n",
      "Worst class : 5 - Cars | IoU: 0.014310664626798987\n",
      "avg IoU: 0.4826614824699731\n",
      "Worst class : 4 - Pedestrians | IoU: 0.10407169898786989\n",
      "avg IoU: 0.5339834812471024\n",
      "Worst class : 3 - Poles | IoU: 0.03163660598991961\n",
      "avg IoU: 0.5866858213235947\n",
      "Worst class : 5 - Cars | IoU: 0.11176871622088945\n"
     ]
    }
   ],
   "source": [
    "num_round = 50\n",
    "param = {'num_leaves': 31, 'max_depth': -1, 'objective': 'multiclass', 'num_class': 6, 'max_bin': 30}\n",
    "\n",
    "for dataset_idx in [0, 1, 2, 3]:\n",
    "    train_multidataset = MultiDataset(datasets[:-1], dataset_idx)\n",
    "    X_train, X_test, y_train, labels_test = train_multidataset.train_test_split()\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    bst = lgb.train(param, train_data, num_round)\n",
    "    y_pred = np.concatenate((np.zeros((X_test.shape[0], 1)), bst.predict(X_test)), axis=1) \n",
    "    labels_pred = np.argmax(y_pred[:, 1:], axis=1) + 1\n",
    "    \n",
    "    res = print_results(labels_test, labels_pred)\n",
    "    print(\"avg IoU:\", res[\"IoU\"].mean())\n",
    "    worst_class = res[\"IoU\"].idxmin()\n",
    "    print(\"Worst class :\", worst_class, \"| IoU:\", res.loc[worst_class, \"IoU\"])\n",
    "    \n",
    "    datasets[dataset_idx].write_GRM(y_pred[:, 1:], Path(\"GRM_data\"), grm_k=11, grm_radius=0.085)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
